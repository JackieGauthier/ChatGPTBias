{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DQ6olPSaR9X6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Combined Dataset Combined_Dataset.Elsx file\n",
        "Final_Data = pd.read_excel('/content/drive/My Drive/Combined_Dataset.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "88AjPN2Sl6wO",
        "outputId": "71c83138-7046-472a-b9fa-50be94584cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Salary by Race and Gender:\n",
            "                     Race  Gender  predictedSalary  deservedSalary\n",
            "0  Asian/Pacific Islander  Female     82732.565848    83739.822248\n",
            "1  Asian/Pacific Islander    Male     80240.453484    82088.642941\n",
            "2                   Black  Female     80431.675795    82440.153587\n",
            "3                   Black    Male     80280.600483    81860.125235\n",
            "4                Hispanic  Female     82330.657672    84663.068240\n",
            "5                Hispanic    Male     82660.231172    83878.687041\n",
            "6         Native American  Female     80162.868304    82278.344668\n",
            "7         Native American    Male     81498.175997    82888.479762\n",
            "8                   White  Female     80455.117600    82922.474379\n",
            "9                   White    Male     80071.727749    81097.315949\n",
            "\n",
            "Average Salary by Race, Gender, and Category:\n",
            "                       Race  Gender                Category  predictedSalary  \\\n",
            "0    Asian/Pacific Islander  Female              ACCOUNTANT     83825.305085   \n",
            "1    Asian/Pacific Islander  Female                ADVOCATE     88505.271186   \n",
            "2    Asian/Pacific Islander  Female             AGRICULTURE     85026.746032   \n",
            "3    Asian/Pacific Islander  Female                 APPAREL     77081.948454   \n",
            "4    Asian/Pacific Islander  Female                    ARTS     97244.029126   \n",
            "..                      ...     ...                     ...              ...   \n",
            "235                   White    Male                      HR     73213.418182   \n",
            "236                   White    Male  INFORMATION-TECHNOLOGY     78110.941667   \n",
            "237                   White    Male        PUBLIC-RELATIONS     84465.000000   \n",
            "238                   White    Male                   SALES     74425.663793   \n",
            "239                   White    Male                 TEACHER     76622.509804   \n",
            "\n",
            "     deservedSalary  \n",
            "0      83826.295702  \n",
            "1      88851.131145  \n",
            "2      84542.918661  \n",
            "3      79516.862834  \n",
            "4      96703.932197  \n",
            "..              ...  \n",
            "235    78506.507364  \n",
            "236    78238.666647  \n",
            "237    85924.763890  \n",
            "238    76459.232168  \n",
            "239    78729.113437  \n",
            "\n",
            "[240 rows x 5 columns]\n",
            "\n",
            "ANOVA test for Predicted Salary by Race: F_onewayResult(statistic=1.3558931352942363, pvalue=0.24656331944043355)\n",
            "ANOVA test for Deserved Salary by Race: F_onewayResult(statistic=1.2071807769274945, pvalue=0.3053569747446988)\n",
            "\n",
            "ANOVA test for Predicted Salary by Gender: F_onewayResult(statistic=0.14694484877230293, pvalue=0.7014755180439177)\n",
            "ANOVA test for Deserved Salary by Gender: F_onewayResult(statistic=1.3218568392607142, pvalue=0.25027015231435923)\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import f_oneway, chi2_contingency\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "Final_Data['adjectives'] = Final_Data[['adjective1', 'adjective2', 'adjective3']].apply(lambda x: ' '.join(x.dropna().astype(str)).lower(), axis=1)\n",
        "\n",
        "# Salary Analysis\n",
        "\n",
        "# Calculate average salaries by race and gender\n",
        "avg_salary_race_gender = Final_Data.groupby(['Race', 'Gender'])[['predictedSalary', 'deservedSalary']].mean().reset_index()\n",
        "\n",
        "# Calculate average salaries by race, gender, and job category\n",
        "avg_salary_race_gender_category = Final_Data.groupby(['Race', 'Gender', 'Category'])[['predictedSalary', 'deservedSalary']].mean().reset_index()\n",
        "\n",
        "# Display the average salary tables\n",
        "print(\"Average Salary by Race and Gender:\")\n",
        "print(avg_salary_race_gender)\n",
        "print(\"\\nAverage Salary by Race, Gender, and Category:\")\n",
        "print(avg_salary_race_gender_category)\n",
        "\n",
        "# Perform separate ANOVA tests for predictedSalary and deservedSalary by Race and Gender\n",
        "\n",
        "# ANOVA test for predictedSalary by Race\n",
        "anova_predicted_race = f_oneway(*[Final_Data[Final_Data['Race'] == race]['predictedSalary'].dropna() for race in Final_Data['Race'].unique()])\n",
        "print(\"\\nANOVA test for Predicted Salary by Race:\", anova_predicted_race)\n",
        "\n",
        "# ANOVA test for deservedSalary by Race\n",
        "anova_deserved_race = f_oneway(*[Final_Data[Final_Data['Race'] == race]['deservedSalary'].dropna() for race in Final_Data['Race'].unique()])\n",
        "print(\"ANOVA test for Deserved Salary by Race:\", anova_deserved_race)\n",
        "\n",
        "# ANOVA test for predictedSalary by Gender\n",
        "anova_predicted_gender = f_oneway(*[Final_Data[Final_Data['Gender'] == gender]['predictedSalary'].dropna() for gender in Final_Data['Gender'].unique()])\n",
        "print(\"\\nANOVA test for Predicted Salary by Gender:\", anova_predicted_gender)\n",
        "\n",
        "# ANOVA test for deservedSalary by Gender\n",
        "anova_deserved_gender = f_oneway(*[Final_Data[Final_Data['Gender'] == gender]['deservedSalary'].dropna() for gender in Final_Data['Gender'].unique()])\n",
        "print(\"ANOVA test for Deserved Salary by Gender:\", anova_deserved_gender)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SUhc3OwUXztQ",
        "outputId": "a5e7e3aa-f598-4a6a-9b52-3b54f9ab6004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Two-Way ANOVA for Predicted Salary (Race and Gender):\n",
            "                        df        sum_sq       mean_sq         F    PR(>F)\n",
            "C(Race)                4.0  1.699137e+10  4.247844e+09  1.355799  0.246597\n",
            "C(Gender)              1.0  4.604021e+08  4.604021e+08  0.146948  0.701472\n",
            "C(Race):C(Gender)      4.0  9.809411e+09  2.452353e+09  0.782726  0.536175\n",
            "Residual           24820.0  7.776335e+13  3.133092e+09       NaN       NaN\n",
            "\n",
            "Two-Way ANOVA for Deserved Salary (Race and Gender):\n",
            "                        df        sum_sq       mean_sq         F    PR(>F)\n",
            "C(Race)                4.0  1.623387e+10  4.058468e+09  1.207070  0.305405\n",
            "C(Gender)              1.0  4.444093e+09  4.444093e+09  1.321763  0.250287\n",
            "C(Race):C(Gender)      4.0  4.720099e+09  1.180025e+09  0.350963  0.843522\n",
            "Residual           24820.0  8.345098e+13  3.362247e+09       NaN       NaN\n"
          ]
        }
      ],
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as ols\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "\n",
        "\n",
        "# Two-Way ANOVA for predictedSalary (Race and Gender)\n",
        "model_predicted = ols.ols('predictedSalary ~ C(Race) + C(Gender) + C(Race):C(Gender)', data=Final_Data).fit()\n",
        "anova_predicted = anova_lm(model_predicted)\n",
        "print(\"\\nTwo-Way ANOVA for Predicted Salary (Race and Gender):\")\n",
        "print(anova_predicted)\n",
        "\n",
        "# Two-Way ANOVA for deservedSalary (Race and Gender)\n",
        "model_deserved = ols.ols('deservedSalary ~ C(Race) + C(Gender) + C(Race):C(Gender)', data=Final_Data).fit()\n",
        "anova_deserved = anova_lm(model_deserved)\n",
        "print(\"\\nTwo-Way ANOVA for Deserved Salary (Race and Gender):\")\n",
        "print(anova_deserved)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjective Analysis\n",
        "\n",
        "# Split adjectives into a list and convert them to lowercase\n",
        "Final_Data['adjective_list'] = Final_Data['adjectives'].str.lower().str.split()\n",
        "\n",
        "# Flatten the list of adjectives across all rows\n",
        "all_adjectives = [adj for sublist in Final_Data['adjective_list'].dropna() for adj in sublist]\n",
        "\n",
        "# Explode the adjective list to prepare for one-hot encoding\n",
        "filtered_data = Final_Data.explode('adjective_list')\n",
        "\n",
        "# One-hot encode all adjectives\n",
        "one_hot_encoded = pd.get_dummies(filtered_data['adjective_list'])\n",
        "\n",
        "# Append race and gender for group-by counts\n",
        "adjective_counts = filtered_data[['Race', 'Gender']].join(one_hot_encoded).groupby(['Race', 'Gender']).sum()\n",
        "\n",
        "# Perform chi-squared test for race\n",
        "chi2_race = chi2_contingency(adjective_counts.groupby(level=0).sum().T)\n",
        "print(\"\\nChi-squared test for adjectives by Race:\", chi2_race)\n",
        "\n",
        "# Perform chi-squared test for gender\n",
        "chi2_gender = chi2_contingency(adjective_counts.groupby(level=1).sum().T)\n",
        "print(\"Chi-squared test for adjectives by Gender:\", chi2_gender)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UNn9fXjysXKi",
        "outputId": "8a764bf0-c1b6-4a52-a7b4-fca7fcd424eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chi-squared test for adjectives by Race: Chi2ContingencyResult(statistic=425.38059508146387, pvalue=1.5134228574935192e-30, dof=140, expected_freq=array([[1269.6, 1269.6, 1269.6, 1269.6, 1269.6],\n",
            "       [ 910.2,  910.2,  910.2,  910.2,  910.2],\n",
            "       [1154.4, 1154.4, 1154.4, 1154.4, 1154.4],\n",
            "       [  57.6,   57.6,   57.6,   57.6,   57.6],\n",
            "       [2529. , 2529. , 2529. , 2529. , 2529. ],\n",
            "       [5762.4, 5762.4, 5762.4, 5762.4, 5762.4],\n",
            "       [ 596.4,  596.4,  596.4,  596.4,  596.4],\n",
            "       [ 205.2,  205.2,  205.2,  205.2,  205.2],\n",
            "       [ 684.6,  684.6,  684.6,  684.6,  684.6],\n",
            "       [1034.4, 1034.4, 1034.4, 1034.4, 1034.4],\n",
            "       [1175.4, 1175.4, 1175.4, 1175.4, 1175.4],\n",
            "       [  70.8,   70.8,   70.8,   70.8,   70.8],\n",
            "       [  57.6,   57.6,   57.6,   57.6,   57.6],\n",
            "       [1930.8, 1930.8, 1930.8, 1930.8, 1930.8],\n",
            "       [  57.6,   57.6,   57.6,   57.6,   57.6],\n",
            "       [ 134.4,  134.4,  134.4,  134.4,  134.4],\n",
            "       [3667.2, 3667.2, 3667.2, 3667.2, 3667.2],\n",
            "       [2562.6, 2562.6, 2562.6, 2562.6, 2562.6],\n",
            "       [ 139.8,  139.8,  139.8,  139.8,  139.8],\n",
            "       [ 210.6,  210.6,  210.6,  210.6,  210.6],\n",
            "       [ 777. ,  777. ,  777. ,  777. ,  777. ],\n",
            "       [ 699.6,  699.6,  699.6,  699.6,  699.6],\n",
            "       [ 652.8,  652.8,  652.8,  652.8,  652.8],\n",
            "       [ 657. ,  657. ,  657. ,  657. ,  657. ],\n",
            "       [ 354. ,  354. ,  354. ,  354. ,  354. ],\n",
            "       [1023. , 1023. , 1023. , 1023. , 1023. ],\n",
            "       [ 212.4,  212.4,  212.4,  212.4,  212.4],\n",
            "       [4617.6, 4617.6, 4617.6, 4617.6, 4617.6],\n",
            "       [4761.6, 4761.6, 4761.6, 4761.6, 4761.6],\n",
            "       [ 569.4,  569.4,  569.4,  569.4,  569.4],\n",
            "       [ 138. ,  138. ,  138. ,  138. ,  138. ],\n",
            "       [4036.8, 4036.8, 4036.8, 4036.8, 4036.8],\n",
            "       [ 447. ,  447. ,  447. ,  447. ,  447. ],\n",
            "       [ 636.6,  636.6,  636.6,  636.6,  636.6],\n",
            "       [ 283.2,  283.2,  283.2,  283.2,  283.2],\n",
            "       [ 617.4,  617.4,  617.4,  617.4,  617.4]]))\n",
            "Chi-squared test for adjectives by Gender: Chi2ContingencyResult(statistic=108.09506002499862, pvalue=2.1831724590986e-09, dof=35, expected_freq=array([[ 3174. ,  3174. ],\n",
            "       [ 2275.5,  2275.5],\n",
            "       [ 2886. ,  2886. ],\n",
            "       [  144. ,   144. ],\n",
            "       [ 6322.5,  6322.5],\n",
            "       [14406. , 14406. ],\n",
            "       [ 1491. ,  1491. ],\n",
            "       [  513. ,   513. ],\n",
            "       [ 1711.5,  1711.5],\n",
            "       [ 2586. ,  2586. ],\n",
            "       [ 2938.5,  2938.5],\n",
            "       [  177. ,   177. ],\n",
            "       [  144. ,   144. ],\n",
            "       [ 4827. ,  4827. ],\n",
            "       [  144. ,   144. ],\n",
            "       [  336. ,   336. ],\n",
            "       [ 9168. ,  9168. ],\n",
            "       [ 6406.5,  6406.5],\n",
            "       [  349.5,   349.5],\n",
            "       [  526.5,   526.5],\n",
            "       [ 1942.5,  1942.5],\n",
            "       [ 1749. ,  1749. ],\n",
            "       [ 1632. ,  1632. ],\n",
            "       [ 1642.5,  1642.5],\n",
            "       [  885. ,   885. ],\n",
            "       [ 2557.5,  2557.5],\n",
            "       [  531. ,   531. ],\n",
            "       [11544. , 11544. ],\n",
            "       [11904. , 11904. ],\n",
            "       [ 1423.5,  1423.5],\n",
            "       [  345. ,   345. ],\n",
            "       [10092. , 10092. ],\n",
            "       [ 1117.5,  1117.5],\n",
            "       [ 1591.5,  1591.5],\n",
            "       [  708. ,   708. ],\n",
            "       [ 1543.5,  1543.5]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Group by Gender and Race, summing over the one-hot encoded adjectives\n",
        "grouped_counts = adjective_counts.groupby(['Gender', 'Race']).sum()\n",
        "\n",
        "# Perform a chi-squared test for race and gender\n",
        "chi2_race_gender = chi2_contingency(grouped_counts)\n",
        "print(\"Chi-squared test for adjectives by Race and Gender:\", chi2_race_gender)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u4MTFWABv39h",
        "outputId": "5cf0beb5-b923-4f77-b134-9a60caf4692c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared test for adjectives by Race and Gender: Chi2ContingencyResult(statistic=895.615193807821, pvalue=4.269785031385703e-57, dof=315, expected_freq=array([[ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7],\n",
            "       [ 634.8,  455.1,  577.2,   28.8, 1264.5, 2881.2,  298.2,  102.6,\n",
            "         342.3,  517.2,  587.7,   35.4,   28.8,  965.4,   28.8,   67.2,\n",
            "        1833.6, 1281.3,   69.9,  105.3,  388.5,  349.8,  326.4,  328.5,\n",
            "         177. ,  511.5,  106.2, 2308.8, 2380.8,  284.7,   69. , 2018.4,\n",
            "         223.5,  318.3,  141.6,  308.7]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "k33KRi6ccJ1A",
        "outputId": "53005ef9-6b3d-4b16-84f8-45bddd3a287a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ecb030922c0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_73c78 th {\n",
              "  font-weight: bold;\n",
              "  background-color: #D9EAD3;\n",
              "}\n",
              "#T_73c78 td {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_73c78_row0_col0, #T_73c78_row0_col1, #T_73c78_row0_col2, #T_73c78_row0_col3, #T_73c78_row0_col4, #T_73c78_row0_col5, #T_73c78_row1_col0, #T_73c78_row1_col1, #T_73c78_row1_col2, #T_73c78_row1_col3, #T_73c78_row1_col4, #T_73c78_row1_col5, #T_73c78_row2_col0, #T_73c78_row2_col1, #T_73c78_row2_col2, #T_73c78_row2_col3, #T_73c78_row2_col4, #T_73c78_row2_col5, #T_73c78_row3_col0, #T_73c78_row3_col1, #T_73c78_row3_col2, #T_73c78_row3_col3, #T_73c78_row3_col4, #T_73c78_row3_col5, #T_73c78_row4_col0, #T_73c78_row4_col1, #T_73c78_row4_col2, #T_73c78_row4_col3, #T_73c78_row4_col4, #T_73c78_row4_col5, #T_73c78_row5_col0, #T_73c78_row5_col1, #T_73c78_row5_col2, #T_73c78_row5_col3, #T_73c78_row5_col4, #T_73c78_row5_col5, #T_73c78_row6_col0, #T_73c78_row6_col1, #T_73c78_row6_col2, #T_73c78_row6_col3, #T_73c78_row6_col4, #T_73c78_row6_col5, #T_73c78_row7_col0, #T_73c78_row7_col1, #T_73c78_row7_col2, #T_73c78_row7_col3, #T_73c78_row7_col4, #T_73c78_row7_col5, #T_73c78_row8_col0, #T_73c78_row8_col1, #T_73c78_row8_col2, #T_73c78_row8_col3, #T_73c78_row8_col4, #T_73c78_row8_col5, #T_73c78_row9_col0, #T_73c78_row9_col1, #T_73c78_row9_col2, #T_73c78_row9_col3, #T_73c78_row9_col4, #T_73c78_row9_col5 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_73c78\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_73c78_level0_col0\" class=\"col_heading level0 col0\" >Race_Gender</th>\n",
              "      <th id=\"T_73c78_level0_col1\" class=\"col_heading level0 col1\" >Top 1</th>\n",
              "      <th id=\"T_73c78_level0_col2\" class=\"col_heading level0 col2\" >Top 2</th>\n",
              "      <th id=\"T_73c78_level0_col3\" class=\"col_heading level0 col3\" >Top 3</th>\n",
              "      <th id=\"T_73c78_level0_col4\" class=\"col_heading level0 col4\" >Top 4</th>\n",
              "      <th id=\"T_73c78_level0_col5\" class=\"col_heading level0 col5\" >Top 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_73c78_row0_col0\" class=\"data row0 col0\" >Asian/Pacific Islander / Female</td>\n",
              "      <td id=\"T_73c78_row0_col1\" class=\"data row0 col1\" >dedicated (951)</td>\n",
              "      <td id=\"T_73c78_row0_col2\" class=\"data row0 col2\" >reliable (785)</td>\n",
              "      <td id=\"T_73c78_row0_col3\" class=\"data row0 col3\" >professional (760)</td>\n",
              "      <td id=\"T_73c78_row0_col4\" class=\"data row0 col4\" >skilled (684)</td>\n",
              "      <td id=\"T_73c78_row0_col5\" class=\"data row0 col5\" >hardworking (603)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_73c78_row1_col0\" class=\"data row1 col0\" >Asian/Pacific Islander / Male</td>\n",
              "      <td id=\"T_73c78_row1_col1\" class=\"data row1 col1\" >dedicated (958)</td>\n",
              "      <td id=\"T_73c78_row1_col2\" class=\"data row1 col2\" >reliable (821)</td>\n",
              "      <td id=\"T_73c78_row1_col3\" class=\"data row1 col3\" >professional (768)</td>\n",
              "      <td id=\"T_73c78_row1_col4\" class=\"data row1 col4\" >skilled (665)</td>\n",
              "      <td id=\"T_73c78_row1_col5\" class=\"data row1 col5\" >hardworking (613)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_73c78_row2_col0\" class=\"data row2 col0\" >Black / Female</td>\n",
              "      <td id=\"T_73c78_row2_col1\" class=\"data row2 col1\" >dedicated (975)</td>\n",
              "      <td id=\"T_73c78_row2_col2\" class=\"data row2 col2\" >reliable (786)</td>\n",
              "      <td id=\"T_73c78_row2_col3\" class=\"data row2 col3\" >professional (784)</td>\n",
              "      <td id=\"T_73c78_row2_col4\" class=\"data row2 col4\" >skilled (685)</td>\n",
              "      <td id=\"T_73c78_row2_col5\" class=\"data row2 col5\" >hardworking (622)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_73c78_row3_col0\" class=\"data row3 col0\" >Black / Male</td>\n",
              "      <td id=\"T_73c78_row3_col1\" class=\"data row3 col1\" >dedicated (974)</td>\n",
              "      <td id=\"T_73c78_row3_col2\" class=\"data row3 col2\" >professional (786)</td>\n",
              "      <td id=\"T_73c78_row3_col3\" class=\"data row3 col3\" >reliable (783)</td>\n",
              "      <td id=\"T_73c78_row3_col4\" class=\"data row3 col4\" >skilled (659)</td>\n",
              "      <td id=\"T_73c78_row3_col5\" class=\"data row3 col5\" >hardworking (618)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_73c78_row4_col0\" class=\"data row4 col0\" >Hispanic / Female</td>\n",
              "      <td id=\"T_73c78_row4_col1\" class=\"data row4 col1\" >dedicated (957)</td>\n",
              "      <td id=\"T_73c78_row4_col2\" class=\"data row4 col2\" >reliable (782)</td>\n",
              "      <td id=\"T_73c78_row4_col3\" class=\"data row4 col3\" >professional (762)</td>\n",
              "      <td id=\"T_73c78_row4_col4\" class=\"data row4 col4\" >skilled (697)</td>\n",
              "      <td id=\"T_73c78_row4_col5\" class=\"data row4 col5\" >hardworking (601)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_73c78_row5_col0\" class=\"data row5 col0\" >Hispanic / Male</td>\n",
              "      <td id=\"T_73c78_row5_col1\" class=\"data row5 col1\" >dedicated (978)</td>\n",
              "      <td id=\"T_73c78_row5_col2\" class=\"data row5 col2\" >reliable (809)</td>\n",
              "      <td id=\"T_73c78_row5_col3\" class=\"data row5 col3\" >professional (742)</td>\n",
              "      <td id=\"T_73c78_row5_col4\" class=\"data row5 col4\" >skilled (673)</td>\n",
              "      <td id=\"T_73c78_row5_col5\" class=\"data row5 col5\" >hardworking (618)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_73c78_row6_col0\" class=\"data row6 col0\" >Native American / Female</td>\n",
              "      <td id=\"T_73c78_row6_col1\" class=\"data row6 col1\" >dedicated (983)</td>\n",
              "      <td id=\"T_73c78_row6_col2\" class=\"data row6 col2\" >reliable (812)</td>\n",
              "      <td id=\"T_73c78_row6_col3\" class=\"data row6 col3\" >professional (807)</td>\n",
              "      <td id=\"T_73c78_row6_col4\" class=\"data row6 col4\" >skilled (731)</td>\n",
              "      <td id=\"T_73c78_row6_col5\" class=\"data row6 col5\" >hardworking (611)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_73c78_row7_col0\" class=\"data row7 col0\" >Native American / Male</td>\n",
              "      <td id=\"T_73c78_row7_col1\" class=\"data row7 col1\" >dedicated (963)</td>\n",
              "      <td id=\"T_73c78_row7_col2\" class=\"data row7 col2\" >reliable (772)</td>\n",
              "      <td id=\"T_73c78_row7_col3\" class=\"data row7 col3\" >professional (744)</td>\n",
              "      <td id=\"T_73c78_row7_col4\" class=\"data row7 col4\" >skilled (676)</td>\n",
              "      <td id=\"T_73c78_row7_col5\" class=\"data row7 col5\" >hardworking (606)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_73c78_row8_col0\" class=\"data row8 col0\" >White / Female</td>\n",
              "      <td id=\"T_73c78_row8_col1\" class=\"data row8 col1\" >dedicated (954)</td>\n",
              "      <td id=\"T_73c78_row8_col2\" class=\"data row8 col2\" >reliable (779)</td>\n",
              "      <td id=\"T_73c78_row8_col3\" class=\"data row8 col3\" >professional (760)</td>\n",
              "      <td id=\"T_73c78_row8_col4\" class=\"data row8 col4\" >skilled (640)</td>\n",
              "      <td id=\"T_73c78_row8_col5\" class=\"data row8 col5\" >hardworking (624)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_73c78_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_73c78_row9_col0\" class=\"data row9 col0\" >White / Male</td>\n",
              "      <td id=\"T_73c78_row9_col1\" class=\"data row9 col1\" >dedicated (911)</td>\n",
              "      <td id=\"T_73c78_row9_col2\" class=\"data row9 col2\" >reliable (807)</td>\n",
              "      <td id=\"T_73c78_row9_col3\" class=\"data row9 col3\" >professional (783)</td>\n",
              "      <td id=\"T_73c78_row9_col4\" class=\"data row9 col4\" >skilled (618)</td>\n",
              "      <td id=\"T_73c78_row9_col5\" class=\"data row9 col5\" >hardworking (596)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Combine the adjectives into a single column\n",
        "Final_Data['adjectives'] = Final_Data[['adjective1', 'adjective2', 'adjective3']].apply(lambda x: ' '.join(x.dropna().astype(str)).lower(), axis=1)\n",
        "\n",
        "# Helper function to get the top 10 adjectives\n",
        "def get_top_adjectives(df, group_by_col):\n",
        "    top_adjectives = []\n",
        "    grouped_data = df.groupby(group_by_col, observed=False)['adjectives'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "    for _, row in grouped_data.iterrows():\n",
        "        group = row[group_by_col]\n",
        "        adjectives = row['adjectives'].split()\n",
        "        most_common = Counter(adjectives).most_common(5)\n",
        "        top_adjectives.append([group] + [f\"{adj} ({count})\" for adj, count in most_common])\n",
        "\n",
        "    # Create a DataFrame for display\n",
        "    columns = [group_by_col] + [f\"Top {i+1}\" for i in range(5)]\n",
        "    return pd.DataFrame(top_adjectives, columns=columns)\n",
        "\n",
        "# Top adjectives by Race\n",
        "top_adjectives_race = get_top_adjectives(Final_Data, 'Race')\n",
        "\n",
        "# Top adjectives by Gender\n",
        "top_adjectives_gender = get_top_adjectives(Final_Data, 'Gender')\n",
        "\n",
        "# Top adjectives by Race and Gender combination\n",
        "Final_Data['Race_Gender'] = Final_Data['Race'].astype(str) + ' / ' + Final_Data['Gender'].astype(str)\n",
        "top_adjectives_race_gender = get_top_adjectives(Final_Data, 'Race_Gender')\n",
        "\n",
        "# Styling function for Excel-like table\n",
        "def style_table(df):\n",
        "    return df.style.set_table_styles(\n",
        "        [\n",
        "            {'selector': 'th', 'props': [('font-weight', 'bold'), ('background-color', '#D9EAD3')]},\n",
        "            {'selector': 'td', 'props': [('text-align', 'center')]},\n",
        "        ]\n",
        "    ).set_properties(**{'text-align': 'center'})\n",
        "\n",
        "# Style the tables\n",
        "styled_race = style_table(top_adjectives_race)\n",
        "styled_gender = style_table(top_adjectives_gender)\n",
        "styled_race_gender = style_table(top_adjectives_race_gender)\n",
        "\n",
        "# Display the styled tables\n",
        "styled_race\n",
        "styled_gender\n",
        "styled_race_gender\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "a5YuEa_mcyYH",
        "outputId": "bf122b97-ba84-49e0-8731-6dd39aae5e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ecb03090430>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_678f5 th {\n",
              "  font-weight: bold;\n",
              "  background-color: #D9EAD3;\n",
              "}\n",
              "#T_678f5 td {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_678f5_row0_col0, #T_678f5_row0_col1, #T_678f5_row0_col2, #T_678f5_row0_col3, #T_678f5_row0_col4, #T_678f5_row0_col5, #T_678f5_row1_col0, #T_678f5_row1_col1, #T_678f5_row1_col2, #T_678f5_row1_col3, #T_678f5_row1_col4, #T_678f5_row1_col5 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_678f5\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_678f5_level0_col0\" class=\"col_heading level0 col0\" >Gender</th>\n",
              "      <th id=\"T_678f5_level0_col1\" class=\"col_heading level0 col1\" >Top 1</th>\n",
              "      <th id=\"T_678f5_level0_col2\" class=\"col_heading level0 col2\" >Top 2</th>\n",
              "      <th id=\"T_678f5_level0_col3\" class=\"col_heading level0 col3\" >Top 3</th>\n",
              "      <th id=\"T_678f5_level0_col4\" class=\"col_heading level0 col4\" >Top 4</th>\n",
              "      <th id=\"T_678f5_level0_col5\" class=\"col_heading level0 col5\" >Top 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_678f5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_678f5_row0_col0\" class=\"data row0 col0\" >Female</td>\n",
              "      <td id=\"T_678f5_row0_col1\" class=\"data row0 col1\" >dedicated (4820)</td>\n",
              "      <td id=\"T_678f5_row0_col2\" class=\"data row0 col2\" >reliable (3944)</td>\n",
              "      <td id=\"T_678f5_row0_col3\" class=\"data row0 col3\" >professional (3873)</td>\n",
              "      <td id=\"T_678f5_row0_col4\" class=\"data row0 col4\" >skilled (3437)</td>\n",
              "      <td id=\"T_678f5_row0_col5\" class=\"data row0 col5\" >hardworking (3061)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_678f5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_678f5_row1_col0\" class=\"data row1 col0\" >Male</td>\n",
              "      <td id=\"T_678f5_row1_col1\" class=\"data row1 col1\" >dedicated (4784)</td>\n",
              "      <td id=\"T_678f5_row1_col2\" class=\"data row1 col2\" >reliable (3992)</td>\n",
              "      <td id=\"T_678f5_row1_col3\" class=\"data row1 col3\" >professional (3823)</td>\n",
              "      <td id=\"T_678f5_row1_col4\" class=\"data row1 col4\" >skilled (3291)</td>\n",
              "      <td id=\"T_678f5_row1_col5\" class=\"data row1 col5\" >hardworking (3051)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "styled_gender\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7TCvnl4Zc9KW",
        "outputId": "97e90496-d9b4-4002-c531-05a0af167eb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ecb03090d60>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_654ba th {\n",
              "  font-weight: bold;\n",
              "  background-color: #D9EAD3;\n",
              "}\n",
              "#T_654ba td {\n",
              "  text-align: center;\n",
              "}\n",
              "#T_654ba_row0_col0, #T_654ba_row0_col1, #T_654ba_row0_col2, #T_654ba_row0_col3, #T_654ba_row0_col4, #T_654ba_row0_col5, #T_654ba_row1_col0, #T_654ba_row1_col1, #T_654ba_row1_col2, #T_654ba_row1_col3, #T_654ba_row1_col4, #T_654ba_row1_col5, #T_654ba_row2_col0, #T_654ba_row2_col1, #T_654ba_row2_col2, #T_654ba_row2_col3, #T_654ba_row2_col4, #T_654ba_row2_col5, #T_654ba_row3_col0, #T_654ba_row3_col1, #T_654ba_row3_col2, #T_654ba_row3_col3, #T_654ba_row3_col4, #T_654ba_row3_col5, #T_654ba_row4_col0, #T_654ba_row4_col1, #T_654ba_row4_col2, #T_654ba_row4_col3, #T_654ba_row4_col4, #T_654ba_row4_col5 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_654ba\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_654ba_level0_col0\" class=\"col_heading level0 col0\" >Race</th>\n",
              "      <th id=\"T_654ba_level0_col1\" class=\"col_heading level0 col1\" >Top 1</th>\n",
              "      <th id=\"T_654ba_level0_col2\" class=\"col_heading level0 col2\" >Top 2</th>\n",
              "      <th id=\"T_654ba_level0_col3\" class=\"col_heading level0 col3\" >Top 3</th>\n",
              "      <th id=\"T_654ba_level0_col4\" class=\"col_heading level0 col4\" >Top 4</th>\n",
              "      <th id=\"T_654ba_level0_col5\" class=\"col_heading level0 col5\" >Top 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_654ba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_654ba_row0_col0\" class=\"data row0 col0\" >Asian/Pacific Islander</td>\n",
              "      <td id=\"T_654ba_row0_col1\" class=\"data row0 col1\" >dedicated (1909)</td>\n",
              "      <td id=\"T_654ba_row0_col2\" class=\"data row0 col2\" >reliable (1606)</td>\n",
              "      <td id=\"T_654ba_row0_col3\" class=\"data row0 col3\" >professional (1528)</td>\n",
              "      <td id=\"T_654ba_row0_col4\" class=\"data row0 col4\" >skilled (1349)</td>\n",
              "      <td id=\"T_654ba_row0_col5\" class=\"data row0 col5\" >hardworking (1216)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_654ba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_654ba_row1_col0\" class=\"data row1 col0\" >Black</td>\n",
              "      <td id=\"T_654ba_row1_col1\" class=\"data row1 col1\" >dedicated (1949)</td>\n",
              "      <td id=\"T_654ba_row1_col2\" class=\"data row1 col2\" >professional (1570)</td>\n",
              "      <td id=\"T_654ba_row1_col3\" class=\"data row1 col3\" >reliable (1569)</td>\n",
              "      <td id=\"T_654ba_row1_col4\" class=\"data row1 col4\" >skilled (1344)</td>\n",
              "      <td id=\"T_654ba_row1_col5\" class=\"data row1 col5\" >hardworking (1240)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_654ba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_654ba_row2_col0\" class=\"data row2 col0\" >Hispanic</td>\n",
              "      <td id=\"T_654ba_row2_col1\" class=\"data row2 col1\" >dedicated (1935)</td>\n",
              "      <td id=\"T_654ba_row2_col2\" class=\"data row2 col2\" >reliable (1591)</td>\n",
              "      <td id=\"T_654ba_row2_col3\" class=\"data row2 col3\" >professional (1504)</td>\n",
              "      <td id=\"T_654ba_row2_col4\" class=\"data row2 col4\" >skilled (1370)</td>\n",
              "      <td id=\"T_654ba_row2_col5\" class=\"data row2 col5\" >hardworking (1219)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_654ba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_654ba_row3_col0\" class=\"data row3 col0\" >Native American</td>\n",
              "      <td id=\"T_654ba_row3_col1\" class=\"data row3 col1\" >dedicated (1946)</td>\n",
              "      <td id=\"T_654ba_row3_col2\" class=\"data row3 col2\" >reliable (1584)</td>\n",
              "      <td id=\"T_654ba_row3_col3\" class=\"data row3 col3\" >professional (1551)</td>\n",
              "      <td id=\"T_654ba_row3_col4\" class=\"data row3 col4\" >skilled (1407)</td>\n",
              "      <td id=\"T_654ba_row3_col5\" class=\"data row3 col5\" >hardworking (1217)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_654ba_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_654ba_row4_col0\" class=\"data row4 col0\" >White</td>\n",
              "      <td id=\"T_654ba_row4_col1\" class=\"data row4 col1\" >dedicated (1865)</td>\n",
              "      <td id=\"T_654ba_row4_col2\" class=\"data row4 col2\" >reliable (1586)</td>\n",
              "      <td id=\"T_654ba_row4_col3\" class=\"data row4 col3\" >professional (1543)</td>\n",
              "      <td id=\"T_654ba_row4_col4\" class=\"data row4 col4\" >skilled (1258)</td>\n",
              "      <td id=\"T_654ba_row4_col5\" class=\"data row4 col5\" >hardworking (1220)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "styled_race"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9sw0-P2pd4TD",
        "outputId": "70362d31-7f3f-4a17-840e-d2a0dff3f639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most Disproportionate Adjectives by Race:\n",
            "Asian/Pacific Islander: engaging (1.26x), technical (1.13x), precise (1.12x), proactive (1.08x), meticulous (1.07x)\n",
            "Black: skillful (1.21x), diligent (1.16x), responsible (1.14x), dynamic (1.12x), motivated (1.1x)\n",
            "Hispanic: expressive (1.33x), energetic (1.3x), communicative (1.19x), educated (1.13x), experienced (1.09x)\n",
            "Native American: problem-solving (1.3x), expressive (1.19x), communicative (1.19x), methodical (1.18x), adaptable (1.08x)\n",
            "White: communicative (1.49x), energetic (1.36x), engaging (1.33x), practical (1.18x), methodical (1.18x)\n",
            "\n",
            "Most Disproportionate Adjectives by Gender:\n",
            "Female: expressive (1.23x), hands-on (1.17x), versatile (1.13x), practical (1.11x), diligent (1.09x)\n",
            "Male: engaging (1.53x), skillful (1.18x), communicative (1.13x), meticulous (1.09x), dynamic (1.09x)\n",
            "\n",
            "Most Disproportionate Adjectives by Race and Gender:\n",
            "Asian/Pacific Islander / Female: practical (1.23x), technical (1.16x), engaging (1.16x), precise (1.15x), detail-oriented (1.12x)\n",
            "Asian/Pacific Islander / Male: engaging (1.29x), meticulous (1.16x), proactive (1.16x), organized (1.11x), strategic (1.1x)\n",
            "Black / Female: hands-on (1.34x), diligent (1.26x), expressive (1.16x), proactive (1.12x), organized (1.08x)\n",
            "Black / Male: skillful (1.48x), responsible (1.25x), dynamic (1.21x), technical (1.16x), communicative (1.16x)\n",
            "Hispanic / Female: energetic (1.31x), expressive (1.29x), resourceful (1.2x), hands-on (1.18x), educated (1.13x)\n",
            "Hispanic / Male: expressive (1.29x), communicative (1.29x), energetic (1.21x), educated (1.09x), experienced (1.08x)\n",
            "Native American / Female: communicative (1.41x), methodical (1.38x), responsible (1.3x), problem-solving (1.21x), expressive (1.16x)\n",
            "Native American / Male: problem-solving (1.31x), engaging (1.29x), detail-oriented (1.25x), passionate (1.21x), expressive (1.16x)\n",
            "White / Female: diligent (1.23x), hands-on (1.18x), versatile (1.17x), strategic (1.17x), communicative (1.16x)\n",
            "White / Male: engaging (1.67x), communicative (1.67x), responsible (1.51x), energetic (1.51x), meticulous (1.39x)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Combine the adjectives into a single column\n",
        "Final_Data['adjectives'] = Final_Data[['adjective1', 'adjective2', 'adjective3']].apply(lambda x: ' '.join(x.dropna().astype(str)).lower(), axis=1)\n",
        "\n",
        "# Helper function to calculate adjective frequencies for each demographic group\n",
        "def calculate_adjective_frequencies(df, group_by_col):\n",
        "    freq_data = {}\n",
        "    grouped_data = df.groupby(group_by_col)['adjectives'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "    for _, row in grouped_data.iterrows():\n",
        "        group = row[group_by_col]\n",
        "        adjectives = row['adjectives'].split()\n",
        "        most_common = Counter(adjectives)\n",
        "        total_count = sum(most_common.values())\n",
        "        # Calculate term frequency (TF)\n",
        "        freq_data[group] = {adj: count / total_count for adj, count in most_common.items()}\n",
        "\n",
        "    return freq_data\n",
        "\n",
        "# Calculate frequencies by Race and Gender\n",
        "freq_by_race = calculate_adjective_frequencies(Final_Data, 'Race')\n",
        "freq_by_gender = calculate_adjective_frequencies(Final_Data, 'Gender')\n",
        "Final_Data['Race_Gender'] = Final_Data['Race'].astype(str) + ' / ' + Final_Data['Gender'].astype(str)\n",
        "freq_by_race_gender = calculate_adjective_frequencies(Final_Data, 'Race_Gender')\n",
        "\n",
        "# Helper function to find the most disproportionate adjectives\n",
        "def find_disproportionate_adjectives(freq_dict):\n",
        "    disproportionate_adjectives = {}\n",
        "\n",
        "    groups = list(freq_dict.keys())\n",
        "    for group in groups:\n",
        "        adjectives = freq_dict[group]\n",
        "        other_groups = [g for g in groups if g != group]\n",
        "        group_results = []\n",
        "\n",
        "        for adj, freq in adjectives.items():\n",
        "            # Calculate average frequency of the adjective in other groups\n",
        "            avg_other_freq = sum(freq_dict[other_group].get(adj, 0) for other_group in other_groups) / len(other_groups)\n",
        "            if avg_other_freq > 0:\n",
        "                # Calculate the disproportionate ratio\n",
        "                ratio = freq / avg_other_freq\n",
        "                if ratio > 1:  # Only consider if it is disproportionately higher\n",
        "                    group_results.append((adj, round(ratio, 2)))\n",
        "\n",
        "        # Sort by the ratio and take the top 5\n",
        "        top_5 = sorted(group_results, key=lambda x: x[1], reverse=True)[:5]\n",
        "        disproportionate_adjectives[group] = top_5\n",
        "\n",
        "    return disproportionate_adjectives\n",
        "\n",
        "# Find the most disproportionate adjectives by Race\n",
        "disproportionate_adjectives_race = find_disproportionate_adjectives(freq_by_race)\n",
        "\n",
        "# Find the most disproportionate adjectives by Gender\n",
        "disproportionate_adjectives_gender = find_disproportionate_adjectives(freq_by_gender)\n",
        "\n",
        "# Find the most disproportionate adjectives by Race and Gender combination\n",
        "disproportionate_adjectives_race_gender = find_disproportionate_adjectives(freq_by_race_gender)\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nMost Disproportionate Adjectives by Race:\")\n",
        "for race, adjectives in disproportionate_adjectives_race.items():\n",
        "    print(f\"{race}: {', '.join([f'{adj} ({ratio}x)' for adj, ratio in adjectives])}\")\n",
        "\n",
        "print(\"\\nMost Disproportionate Adjectives by Gender:\")\n",
        "for gender, adjectives in disproportionate_adjectives_gender.items():\n",
        "    print(f\"{gender}: {', '.join([f'{adj} ({ratio}x)' for adj, ratio in adjectives])}\")\n",
        "\n",
        "print(\"\\nMost Disproportionate Adjectives by Race and Gender:\")\n",
        "for race_gender, adjectives in disproportionate_adjectives_race_gender.items():\n",
        "    print(f\"{race_gender}: {', '.join([f'{adj} ({ratio}x)' for adj, ratio in adjectives])}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}